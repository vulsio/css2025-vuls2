\section{評価}

第2章で述べた提案手法に基づき，脆弱性情報の収集および管理システムを実装した．本章では，実装したシステムを用いて，提案手法が広範な脆弱性情報を統合的に管理可能にし，また追跡可能性を向上させるかを評価し，その有効性を明らかにする．

\subsection{システム実装と成果物}

提案手法の設計に基づき，脆弱性情報の収集および管理システムを実装した．本システムの主要な成果物は以下の通りである．

\begin{itemize}
  \item データハーベストツール\footnote{\url{https://github.com/MaineK00n/vuls-data-update}}
  \item データベース構築ツール\footnote{\url{https://github.com/vulsio/vuls-data-db}}
  \item 収集および変換されたデータ(履歴付き)\footnote{\url{https://github.com/vulsio/vuls-data-db/pkgs/container/vuls-data-db}}
  \item 構築されたデータベース(履歴付き)\footnote{\url{https://github.com/vulsio/vuls-nightly-db/pkgs/container/vuls-nightly-db}}
\end{itemize}

本システムは，執筆時点において12時間ごとにデータ収集からデータベース構築までの一連のデータハーベスト処理を自動的に実行している．

\subsection{広範な脆弱性情報の収集}

fetch ステージは，可能な限り一次情報源からの脆弱性データ収集を実現した．具体的には，MITRE CVEやNIST NVDといった主要な脆弱性情報源に加え，OSディストリビューションベンダ（Microsoft，Red Hat，Ubuntuなど），ネットワークベンダ（Fortinet，Cisco，Palo Altoなど），およびプログラミング言語関連の脆弱性情報も網羅的に収集している．執筆時点での収集対象は141種類に上り，これにより広範な脆弱性情報を一元的に管理することが可能となった．

fetch ステージはCIジョブとして定義\footnote{\url{https://github.com/vulsio/vuls-data-db/blob/main/.github/workflows/fetch-all.yml}}されており．執筆時点では1日に2回起動しデータ収集を行う．

\subsection{統合されたデータフォーマットの実現}

収集される脆弱性データは，それぞれ異なるフォーマットで提供されている．例えば，OVALやCSAF/VEXのように規格化されたフォーマットであっても，その内部における情報の記述方法はベンダごとに多様であり，単にフォーマット規格に準拠しているだけでは，その解釈に一貫性を持たせることは困難である．

extractステージの実装により，これらの差異や解釈方法を吸収し，統合されたデータ形式\footnote{\url{https://github.com/MaineK00n/vuls-data-update/blob/nightly/pkg/extract/types/data/data.go}}への変換を実現した．このデータ形式のうち，脆弱性検知に用いられる主要な情報を以下に示す．

\begin{description}
  \item [エコシステム] \mbox{} \\
    検知対象の環境を表す．例として \texttt{redhat:9} や \texttt{ubuntu:24.04} などが挙げられる．
  \item [パッケージ] \mbox{} \\
    脆弱性が存在する単位を表す．ソースパッケージかバイナリパッケージかの区別，パッケージ名，またはCPE文字列などを含む．
  \item [影響を受けるバージョン範囲] \mbox{} \\
    脆弱性が存在するバージョン範囲．\texttt{less than}，\texttt{equal} などの条件表現やそられの組み合わせを記述でき，バージョン範囲を柔軟に表現できる．バージョン文字列の解釈方法(e.g. セマンティックバージョニング，RPM 形式)も合わせて明示している．
\end{description}

このvuls-data-extractedフォーマットにより，元のデータで暗黙的に仮定されていたソースパッケージとバイナリパッケージの区別や，バージョン情報の解釈方法を事前に把握しておく必要がなくなり，明示された記述に従って情報を解釈するだけでよくなった．これにより，後続のデータベース構築や，そのデータベースを用いた脆弱性検知におけるフォーマット依存性が劇的に減少した．また，Red HatのOVALとCSAF/VEXのように，フォーマットが異なる脆弱性情報の比較も容易になっている．執筆時点では，24種類の情報源に対するvuls-data-extractedフォーマット化が完了している．

extract ステージもCIジョブとして定義\footnote{\url{https://github.com/vulsio/vuls-data-db/blob/main/.github/workflows/extract-all.yml}}されており，fetchステージに続いて実行される．

\subsection{履歴管理機能の実装と追跡可能性・再現性の向上}

本システムに実装された履歴管理機能は，脆弱性情報の追跡可能性と脆弱性検知結果の再現性という2つの側面から，脆弱性管理の質を大幅に向上させることが明らかになった．

\subsubsection{変更履歴の追跡による検知結果変動の原因分析}

本システムの第一の利点は，脆弱性情報の変更履歴を追跡し，それによって検知結果の変動原因を分析できる点にある．これにより，脆弱性情報がどのように変更されたかを可視化し，検知結果の変化に対する客観的な説明を可能にする．以下にRed Hat Enterprise Linux向けVEXフォーマットによる脆弱性情報の変化の具体例を示す．

この vuls-data-extracted フォーマットのデータは GitHub Container Repository \texttt{vuls-data-db}\footnote{\url{https://github.com/vulsio/vuls-data-db/pkgs/container/vuls-data-db}}にあり，タグ\texttt{vuls-data-extracted-redhat-vex-rhel}で取得できる\footnote{取得したバイナリを Zstandard で展開すると Gitの管理用ディレクトリ \texttt{.git/} だけが入った構造になっている．Git 操作で履歴取得やファイル閲覧が可能である．}．

\paragraph{OS パッケージに対するステータスの変化}
特定の脆弱性情報において，修正ステータスが「Out of support scope」から「Affected」へと変化する事例が確認された．具体的には，CVE-2024-0229 における \texttt{redhat:6} のOSパッケージ \texttt{tigervnc} に対する評価をみると，コミット \texttt{8c5e6158b4}（2025-07-10 15:03）では 「Out of support scope」であったが，その次のコミット\texttt{3e8d8d3bf5}（2025-07-11 05:07）で「Affected」へと変更されてたことが確認できた．

これは，サポート対象外とされていたパッケージが，後に影響を受けるものとして再分類されたことを意味する．本機能により，このようなステータスの変更がいつ，どのように発生したかを明確に把握できる．

\paragraph{特定のCVE IDに対する情報が消滅する事例}
ある時点で存在していた CVE-2024-24791 に関する情報が，その後の更新でシステムから消滅した事例が確認された．
具体的にはコミット \texttt{708ff21dc6}（2025-07-10 15:03:39）では CVE-2024-24791 のデータが存在する一方で，その次のコミット \texttt{e4787b5085}（2025-07-18 03:47）では該当 CVE データのファイルが存在しない．

この情報の削除の直接的な理由は不明であるが，データ提供者のポリシー変更やデータ生成時のエラーなど複数の可能性が考えられる．重要なのは，本方式がこのような「原因不明の変更」をも客観的な事実として捉え，その後の調査の起点とできる点にある．なお，Red Hatの VEX フォーマット以外の公式情報源である \cite{rh-cve-2024-24791-1} \cite{rh-cve-2024-24791-2} には，削除が確認された日 2025年7月18日 とその約1週間後の 2025年7月24日には情報が掲載されていたことを補足する．

\paragraph{Red Hat 10に対する情報のみが消滅する事例}
CVE-2024-43420に関する情報において，当初は\texttt{redhat:6}，\texttt{redhat:8}，\texttt{redhat:9}, \texttt{redhat:10}のエコシステムに対する検出情報が含まれていたが，その後の更新で\texttt{redhat:10}に関する情報のみが消滅した．具体的にはコミット \texttt{8c5e6158b4}（2025-07-10 15:03:39） では CVE-2024-43420 のデータに \texttt{redhat:10} が含まれていたが，その次のコミット \texttt{3e8d8d3bf5}（2025-07-10 15:03:39）では含まれなくなっていた．

このような特定のバージョンに対する情報の削除も，履歴管理機能によって明確に把握でき，影響範囲の特定や原因究明に役立つ．

以上のように，取得したタイミングに依存せず，明確なコミットハッシュという ID を示しつつ脆弱性データの変更点のトラッキングが可能になった．また，それはパブリックなインターネット上に公開されているため，誰でも変更について確認し，議論できる土台を提供する．

\subsubsection{特定時点における検知の再現性}

本システムの第二の利点は，特定の時点における脆弱性検知の再現性を可能にする点である．これは，脆弱性データベースを固定することで実現される．

従来，脆弱性情報を各自が任意のタイミングで取得していたため，「昨日の13時頃に取得したデータを使っている」といった曖昧な認識合わせしかできなかった．しかし，本方式では脆弱性データベースをそのハッシュ値で保存および参照することにより，検知結果の再現性を確実に保証できるようになった．検知ロジック自体はソースコードがGit管理されているため再現性が高いが，これに加えて脆弱性データ側の再現性を高めることができた点は極めて重要である．

例えば，バグ報告の issue \cite{issue-2198}では，確実な再現性のため \texttt{config.toml}設定ファイルのなかで脆弱性データベースのハッシュ値を明示的に指定している．こうすることで，以前は難しかった常に同じデータセットを用いた検知が可能となる．
データベースのハッシュ値が分かると，そのなかのメタデータに extracted と raw データの Git コミットハッシュが記されているため，一次情報源に近いところまで遡った調査も可能となる．

これは，バグ報告やセキュリティ監査など，特定の時点での状況を正確に再現する必要がある場合に，極めて強力な機能となる．

\subsection{エンジニアリング上の利点（補足）}

本方式は，上記の本質的な利点に加え，エンジニアリング面でもいくつかの恩恵をもたらした．

\begin{description}
  \item[脆弱性データ提供サーバへの依存性低減] \mbox{} \\
    脆弱性データをGitHub Container Registryに配置することで，各脆弱性データ提供サーバの状態（応答不能など）に直接依存することなく，データベースを生成できるようになった．これにより，DB生成時のエラー発生可能性が大幅に減少し，システムの堅牢性が向上した．
  \item[DB生成時間の安定化] \mbox{} \\
    上記の依存性低減と関連して，データベース生成にかかる時間が安定し，予測可能になった．これは運用上の大きなメリットとなる．
\end{description}
